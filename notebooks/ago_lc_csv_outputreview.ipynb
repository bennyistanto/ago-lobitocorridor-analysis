{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69bc89e-1cf8-4594-9f3a-10e5e6c8d42e",
   "metadata": {},
   "source": [
    "# Validation check for Step 00 - 14 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b496080-ec59-42ff-8a68-dfbf3a34855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== File presence check (project outputs + /mnt/data fallback) ===\n",
      "iso          -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_kpis_isochrones.csv\n",
      "risk         -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_roads_flood_risk_summary.csv\n",
      "muni         -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_municipality_indicators.csv\n",
      "corr         -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_corr_with_rural_poverty.csv\n",
      "prof         -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_municipality_profiles.csv\n",
      "rank         -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_priority_muni_rank.csv\n",
      "scn_meta     -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_priority_scenarios.meta.json\n",
      "scn_sum      -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_priority_scenarios_summary.csv\n",
      "site         -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_site_audit_points.csv\n",
      "proj         -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_project_kpis.csv\n",
      "lookup       -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_admin2_lookup.csv\n",
      "admin2_rank  -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_priority_admin2_rank.csv\n",
      "clusters     -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_priority_clusters.csv\n",
      "catch_kpi    -> MISSING | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_catchments_kpis.csv\n",
      "clust_syn    -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_cluster_synergies.csv\n",
      "site_syn     -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_site_synergies.csv\n",
      "od_grav      -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_od_gravity.csv\n",
      "od_zone      -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_od_zone_attrs.csv\n",
      "od_agents    -> FOUND | /mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables/moxicoleste_od_agents.csv\n",
      "\n",
      "[Isochrones] PASS shape=(4, 15)\n",
      "  monotonic pop/cells: PASS\n",
      "        aoi  travel_cut_min    pop_within  cells_within  area_km2_within   pop_pct  cropland_km2  cropland_pct  electrified_cells  electrified_pct  cell_area_km2  note_electrification_denominator_zero   pop_total  cropland_total_km2  electrified_total_cells\n",
      "moxicoleste            30.0 246630.296875        1250.0           1250.0 66.290570     16.569998     31.951403                0.0              NaN            1.0                                   True 372044.3125           51.860001                      0.0\n",
      "moxicoleste            60.0 271239.031250        3014.0           3014.0 72.905034     21.190001     40.860008                0.0              NaN            1.0                                   True 372044.3125           51.860001                      0.0\n",
      "moxicoleste           120.0 306827.531250        8529.0           8529.0 82.470695     25.130001     48.457387                0.0              NaN            1.0                                   True 372044.3125           51.860001                      0.0\n",
      "[Roads×Flood] ranges: PASS\n",
      "  total_road_cells: 7227\n",
      "  total_risk_cells: 4391\n",
      "  risk_near_priority_cells: 51\n",
      "  method: Risk=roads ∩ flood; near-priority=within 1 cell of Top10% priority; method=fraction≥0.25; roads_all_touched=False\n",
      "  fraction_min: 0.25\n",
      "[Muni indicators] PASS rows=4 unique_adm2=4\n",
      "  mean numeric NA share: 0.00%\n",
      "  sample cols: ADM2CD_c, NAM_2, NAM_1, communications__telephone, communications__internet, communications__newspaper, communications__radio, communications__television, communications__none, foodinsecurity__went_without_food ...\n",
      "[Muni correlations] n<=#ADM2: PASS n_max=4 #ADM2=4\n",
      "         theme                    var        r        p  n\n",
      "       outflow insufficient_transport 0.999998 0.000002  4\n",
      "communications                   none 0.999994 0.000006  4\n",
      "   productions      diff_access_water 0.999987 0.000013  4\n",
      "foodinsecurity      few_types_of_food 0.999978 0.000022  4\n",
      "   productions    lack_agri_equipment 0.999923 0.000077  4\n",
      "[Profiles] quintile present: PASS rows=4\n",
      "  quintile counts:\n",
      " poverty_quintile\n",
      "4    1\n",
      "5    1\n",
      "1    1\n",
      "2    1\n",
      "Name: count, dtype: int64\n",
      "[Muni shortlist] columns: PASS shape=(4, 18)\n",
      "  optional cols present: food_insec_scale, pct_priority, poverty_rural, rural_pop_est, rwi_mean\n",
      "[Muni shortlist] unique ADM2CD_c: PASS rows=4 unique=4\n",
      "  score range [0-1]: PASS [0.0794, 0.6114]\n",
      "[Scenarios] ids match meta: PASS count=4\n",
      "  overlap_pct_vs_baseline: min=nan mean=nan max=nan\n",
      "  jaccard_vs_baseline: min=nan mean=nan max=nan\n",
      "  selected_cells: min=0.00 mean=0.00 max=0.00\n",
      "  selected_km2: min=0.00 mean=0.00 max=0.00\n",
      "[Site audit points] has XY: PASS shape=(0, 16)\n",
      "[Project KPIs] shape: (0, 28)\n",
      "[Admin2 Lookup] columns: PASS shape=(4, 4)\n",
      "  unique ADM2CD_c: PASS\n",
      "  sequential lab: PASS\n",
      "  provinces: Moxico Leste\n",
      "  municipalities: 4\n",
      " lab  ADM2CD_c        NAM_1         NAM_2\n",
      "   1 AGO019001 Moxico Leste  Alto Zambeze\n",
      "   2 AGO019003 Moxico Leste Kameia Lumege\n",
      "   3 AGO019005 Moxico Leste       Luacano\n",
      "[Priority Admin2 Rank] columns: PASS shape=(1, 13)\n",
      "  contiguous ranks: PASS\n",
      "  rank range: 1 to 1\n",
      "  score range [0-1]: PASS [0.7319, 0.7319]\n",
      "  selected municipalities: 0/1 (0.0%)\n",
      "  share_selected range [0-1]: PASS [0.0000, 0.0000]\n",
      "  Top 5 priority municipalities:\n",
      "       NAM_2    score  rank  selected\n",
      "Alto Zambeze 0.731893     1     False\n",
      "[Priority clusters] present: PASS shape=(0, 20)\n",
      "  sample cols: cluster_id\n",
      "Empty DataFrame\n",
      "Columns: [cluster_id]\n",
      "Index: []\n",
      "[Catchments KPIs] MISSING or EMPTY\n",
      "[Cluster synergies] present: PASS shape=(0, 15)\n",
      "  columns: cluster_id, lon, lat, dist_km_nearest_gov, dist_km_nearest_wb, dist_km_nearest_oth, count_gov_le5km, count_wb_le5km, count_oth_le5km, count_gov_le10km, count_wb_le10km, count_oth_le10km ...\n",
      "[Site synergies] present: PASS shape=(0, 15)\n",
      "  columns: site_id, lon, lat, dist_km_nearest_gov, dist_km_nearest_wb, dist_km_nearest_oth, count_gov_le5km, count_wb_le5km, count_oth_le5km, count_gov_le10km, count_wb_le10km, count_oth_le10km ...\n",
      "[OD zone attrs] has lon/lat: PASS | has zone id: PASS shape=(4, 8)\n",
      "[OD gravity] columns: PASS rows=16\n",
      "  non-negative flows: PASS\n",
      "  total trips=1,000,000 | flow-weighted mean dist=24.0 km\n",
      "  mean asymmetry |F - F^T| = 0.00\n",
      "[OD agents] columns: PASS N=16\n",
      "  o_lon in [-180,180]: 100.00%\n",
      "  d_lon in [-180,180]: 100.00%\n",
      "  o_lat in [-90,90]: 100.00%\n",
      "  d_lat in [-90,90]: 100.00%\n",
      "\n",
      "================================================================================\n",
      "CROSS-FILE VALIDATION\n",
      "================================================================================\n",
      "[Lookup ↔ Admin2 Rank] ADM2CD_c match: FAIL\n",
      "  Missing in rank (first 10): ['AGO019003', 'AGO019005', 'AGO019006']\n",
      "[Lookup ↔ Muni Indicators] count match: PASS lookup=4 muni_unique=4\n",
      "[Admin2 Rank ↔ Muni shortlist] ADM2CD_c match: FAIL\n",
      "  In muni_rank but not admin2_rank (first 10): ['AGO019003', 'AGO019005', 'AGO019006']\n",
      "[OD zones ↔ Lookup] zone count matches: PASS zones=4 lookup=4\n",
      "\n",
      "================================================================================\n",
      "VALIDATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, pandas as pd, numpy as np\n",
    "\n",
    "# ---------- Config ----------\n",
    "AOI = \"moxicoleste\"  # change if needed\n",
    "# Primary project outputs path\n",
    "B1 = Path(\"/mnt/c/Users/benny/OneDrive/Documents/Github/ago-lobitocorridor-analysis/outputs/tables\")\n",
    "# Fallback for ad-hoc uploads provided in this session\n",
    "B2 = Path(\"/mnt/d/temp/wbg/iso3/ago/lobitocorridor/outputs/tables\")\n",
    "\n",
    "SEARCH_DIRS = [B1, B2]\n",
    "\n",
    "def resolve(fname: str) -> Path:\n",
    "    for base in SEARCH_DIRS:\n",
    "        p = base / fname\n",
    "        if p.exists():\n",
    "            return p\n",
    "    # Not found anywhere -> return default in B1 so messages still show path\n",
    "    return B1 / fname\n",
    "\n",
    "def ok(x): return \"PASS\" if x else \"FAIL\"\n",
    "def exists_nonempty(p: Path) -> bool:\n",
    "    try:\n",
    "        return p.exists() and p.stat().st_size > 0\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# ---------- Known / expected filenames ----------\n",
    "paths = {\n",
    "    # Step 00–10 (yours, unchanged)\n",
    "    \"iso\":        resolve(f\"{AOI}_kpis_isochrones.csv\"),\n",
    "    \"risk\":       resolve(f\"{AOI}_roads_flood_risk_summary.csv\"),\n",
    "    \"muni\":       resolve(f\"{AOI}_municipality_indicators.csv\"),\n",
    "    \"corr\":       resolve(f\"{AOI}_corr_with_rural_poverty.csv\"),\n",
    "    \"prof\":       resolve(f\"{AOI}_municipality_profiles.csv\"),\n",
    "    \"rank\":       resolve(f\"{AOI}_priority_muni_rank.csv\"),\n",
    "    \"scn_meta\":   resolve(f\"{AOI}_priority_scenarios.meta.json\"),\n",
    "    \"scn_sum\":    resolve(f\"{AOI}_priority_scenarios_summary.csv\"),\n",
    "    \"site\":       resolve(f\"{AOI}_site_audit_points.csv\"),\n",
    "    \"proj\":       resolve(f\"{AOI}_project_kpis.csv\"),\n",
    "    \"lookup\":     resolve(f\"{AOI}_admin2_lookup.csv\"),\n",
    "    \"admin2_rank\":resolve(f\"{AOI}_priority_admin2_rank.csv\"),\n",
    "    \"clusters\":   resolve(f\"{AOI}_priority_clusters.csv\"),\n",
    "    \"catch_kpi\":  resolve(f\"{AOI}_catchments_kpis.csv\"),\n",
    "    \"clust_syn\":  resolve(f\"{AOI}_cluster_synergies.csv\"),\n",
    "    \"site_syn\":   resolve(f\"{AOI}_site_synergies.csv\"),\n",
    "    \"od_grav\":    resolve(f\"{AOI}_od_gravity.csv\"),\n",
    "    \"od_zone\":    resolve(f\"{AOI}_od_zone_attrs.csv\"),\n",
    "    \"od_agents\":  resolve(f\"{AOI}_od_agents.csv\"),\n",
    "}\n",
    "\n",
    "print(\"=== File presence check (project outputs + /mnt/data fallback) ===\")\n",
    "for k, p in paths.items():\n",
    "    print(f\"{k:12s} ->\", \"FOUND\" if p.exists() else \"MISSING\", f\"| {p}\")\n",
    "print()\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Isochrones (Step 05/08)\n",
    "# ------------------------------\n",
    "try:\n",
    "    p = paths[\"iso\"]\n",
    "    if exists_nonempty(p):\n",
    "        iso = pd.read_csv(p)\n",
    "        exp = {\"aoi\",\"travel_cut_min\",\"pop_within\",\"cells_within\",\"area_km2_within\"}\n",
    "        print(\"[Isochrones]\", ok(exp.issubset(iso.columns)), f\"shape={iso.shape}\")\n",
    "        iso_s = iso.sort_values(\"travel_cut_min\")\n",
    "        mono_pop   = (iso_s[\"pop_within\"].diff().fillna(0)  >= -1e-6).all()\n",
    "        mono_cells = (iso_s[\"cells_within\"].diff().fillna(0) >= -1e-6).all()\n",
    "        print(\"  monotonic pop/cells:\", ok(mono_pop and mono_cells))\n",
    "        print(iso.head(3).to_string(index=False))\n",
    "    else:\n",
    "        print(\"[Isochrones] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Isochrones] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Roads × Flood\n",
    "# ------------------------------\n",
    "try:\n",
    "    p = paths[\"risk\"]\n",
    "    if exists_nonempty(p):\n",
    "        risk = pd.read_csv(p)\n",
    "        if not risk.empty:\n",
    "            r = risk.iloc[0]\n",
    "            def fnum(k):\n",
    "                try: return float(r.get(k, np.nan))\n",
    "                except: return np.nan\n",
    "            ok_range = (0 <= fnum(\"risk_pct_of_roads\") <= 100) and (0 <= fnum(\"near_prio_pct_of_risk\") <= 100)\n",
    "            print(\"[Roads×Flood] ranges:\", ok(ok_range))\n",
    "            for k in [\"total_road_cells\",\"total_risk_cells\",\"risk_near_priority_cells\"]:\n",
    "                print(f\"  {k}:\", r.get(k, \"<missing>\"))\n",
    "            print(\"  method:\", r.get(\"notes\",\"\"))\n",
    "            print(\"  fraction_min:\", r.get(\"flood_exceed_fraction_min\", np.nan))\n",
    "        else:\n",
    "            print(\"[Roads×Flood] EMPTY\")\n",
    "    else:\n",
    "        print(\"[Roads×Flood] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Roads×Flood] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Municipality indicators\n",
    "# ------------------------------\n",
    "muni = None\n",
    "try:\n",
    "    p = paths[\"muni\"]\n",
    "    if exists_nonempty(p):\n",
    "        muni = pd.read_csv(p)\n",
    "        idc = [c for c in [\"ADM2CD_c\",\"NAM_1\",\"NAM_2\"] if c in muni.columns]\n",
    "        n_unique = len(muni[idc].drop_duplicates()) if idc else None\n",
    "        print(\"[Muni indicators]\", ok(n_unique==len(muni)),\n",
    "              f\"rows={len(muni)} unique_adm2={n_unique}\")\n",
    "        num = muni.select_dtypes(include=\"number\")\n",
    "        na_mean = float(num.isna().mean().mean()) if not num.empty else np.nan\n",
    "        print(\"  mean numeric NA share:\", f\"{na_mean:.2%}\")\n",
    "        print(\"  sample cols:\", \", \".join(list(muni.columns)[:10]), \"...\")\n",
    "    else:\n",
    "        print(\"[Muni indicators] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Muni indicators] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Correlations\n",
    "# ------------------------------\n",
    "try:\n",
    "    p = paths[\"corr\"]\n",
    "    if exists_nonempty(p):\n",
    "        corr = pd.read_csv(p)\n",
    "        if not corr.empty and {\"theme\",\"var\",\"r\",\"p\",\"n\"}.issubset(corr.columns):\n",
    "            n_max = int(pd.to_numeric(corr[\"n\"], errors=\"coerce\").max())\n",
    "            n_rows = len(muni) if muni is not None else None\n",
    "            print(\"[Muni correlations] n<=#ADM2:\", ok(n_rows is None or n_max <= n_rows),\n",
    "                  f\"n_max={n_max} #ADM2={n_rows}\")\n",
    "            top = corr.assign(absr=np.abs(pd.to_numeric(corr[\"r\"], errors=\"coerce\")))\\\n",
    "                      .sort_values(\"absr\", ascending=False).head(5)\n",
    "            print(top[[\"theme\",\"var\",\"r\",\"p\",\"n\"]].to_string(index=False))\n",
    "        else:\n",
    "            print(\"[Muni correlations] present but missing cols or EMPTY\")\n",
    "    else:\n",
    "        print(\"[Muni correlations] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Muni correlations] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 5) Profiles\n",
    "# ------------------------------\n",
    "try:\n",
    "    p = paths[\"prof\"]\n",
    "    if exists_nonempty(p):\n",
    "        prof = pd.read_csv(p)\n",
    "        has_q = \"poverty_quintile\" in prof.columns\n",
    "        print(\"[Profiles] quintile present:\", ok(has_q), f\"rows={len(prof)}\")\n",
    "        if has_q:\n",
    "            print(\"  quintile counts:\\n\", prof[\"poverty_quintile\"].value_counts(dropna=False))\n",
    "    else:\n",
    "        print(\"[Profiles] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Profiles] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 6) Municipality shortlist (Step 09)\n",
    "# ------------------------------\n",
    "try:\n",
    "    p = paths[\"rank\"]  # {AOI}_priority_muni_rank.csv\n",
    "    if exists_nonempty(p):\n",
    "        rank = pd.read_csv(p)\n",
    "\n",
    "        # Required core columns for the Step 09 shortlist\n",
    "        required = {\n",
    "            \"ADM2CD_c\", \"NAM_1\", \"NAM_2\",\n",
    "            \"area_km2\", \"pop_total\",\n",
    "            \"pop_le60min\", \"pop_le120min\", \"pop_gt120min\",\n",
    "            \"cropland_km2\", \"pct_electrified\", \"pct_rural\",\n",
    "            \"score\",\n",
    "        }\n",
    "        has_required = required.issubset(rank.columns)\n",
    "        print(\"[Muni shortlist] columns:\", ok(has_required), f\"shape={rank.shape}\")\n",
    "        if not has_required:\n",
    "            missing = sorted(required - set(rank.columns))\n",
    "            print(\"  missing required cols:\", missing)\n",
    "\n",
    "        # Optional extras (including rural pop / rural poor if you added them in Step 09)\n",
    "        optional = {\n",
    "            \"pct_priority\", \"poverty_rural\", \"food_insec_scale\",\n",
    "            \"rwi_mean\", \"rural_pop_est\", \"rural_poor_est\",\n",
    "        }\n",
    "        extras_present = sorted(optional & set(rank.columns))\n",
    "        if extras_present:\n",
    "            print(\"  optional cols present:\", \", \".join(extras_present))\n",
    "\n",
    "        # 1 row per ADM2 sanity check\n",
    "        if \"ADM2CD_c\" in rank.columns:\n",
    "            n_unique = rank[\"ADM2CD_c\"].nunique()\n",
    "            uniq_ok = (n_unique == len(rank))\n",
    "            print(\"[Muni shortlist] unique ADM2CD_c:\", ok(uniq_ok),\n",
    "                  f\"rows={len(rank)} unique={n_unique}\")\n",
    "\n",
    "        # Score in [0,1] sanity check\n",
    "        if \"score\" in rank.columns:\n",
    "            smin = float(rank[\"score\"].min())\n",
    "            smax = float(rank[\"score\"].max())\n",
    "            score_ok = (0 <= smin <= 1) and (0 <= smax <= 1)\n",
    "            print(\"  score range [0-1]:\", ok(score_ok), f\"[{smin:.4f}, {smax:.4f}]\")\n",
    "    else:\n",
    "        print(\"[Muni shortlist] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Muni shortlist] ERROR:\", e)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 7) Scenarios meta/summary\n",
    "# ------------------------------\n",
    "try:\n",
    "    scn_ids_meta = []\n",
    "    pm = paths[\"scn_meta\"]\n",
    "    if exists_nonempty(pm):\n",
    "        meta = json.loads(pm.read_text())\n",
    "        if isinstance(meta, list):\n",
    "            scn_ids_meta = [d.get(\"id\") for d in meta if isinstance(d, dict)]\n",
    "    ps = paths[\"scn_sum\"]\n",
    "    if exists_nonempty(ps):\n",
    "        scn = pd.read_csv(ps)\n",
    "        scn_ids_sum = sorted(scn[\"scenario_id\"].unique()) if \"scenario_id\" in scn else []\n",
    "        scn_ok = not scn_ids_meta or (set(scn_ids_meta) == set(scn_ids_sum))\n",
    "        print(\"[Scenarios] ids match meta:\", ok(scn_ok), f\"count={len(scn_ids_sum)}\")\n",
    "        for k in [\"overlap_pct_vs_baseline\",\"jaccard_vs_baseline\",\"selected_cells\",\"selected_km2\"]:\n",
    "            if k in scn:\n",
    "                print(f\"  {k}: min={scn[k].min():.2f} mean={scn[k].mean():.2f} max={scn[k].max():.2f}\")\n",
    "    else:\n",
    "        print(\"[Scenarios] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Scenarios] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 8) Site audit points\n",
    "# ------------------------------\n",
    "try:\n",
    "    p = paths[\"site\"]\n",
    "    if exists_nonempty(p):\n",
    "        site = pd.read_csv(p)\n",
    "        cols = {c.lower() for c in site.columns}\n",
    "        has_xy = any(c in cols for c in [\"x\",\"lon\",\"longitude\"]) and any(c in cols for c in [\"y\",\"lat\",\"latitude\"])\n",
    "        print(\"[Site audit points] has XY:\", ok(has_xy), f\"shape={site.shape}\")\n",
    "    else:\n",
    "        print(\"[Site audit points] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Site audit points] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 9) Project KPIs\n",
    "# ------------------------------\n",
    "try:\n",
    "    p = paths[\"proj\"]\n",
    "    if exists_nonempty(p):\n",
    "        proj = pd.read_csv(p)\n",
    "        print(\"[Project KPIs] shape:\", proj.shape)\n",
    "    else:\n",
    "        print(\"[Project KPIs] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Project KPIs] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 10) Admin2 Lookup\n",
    "# ------------------------------\n",
    "lookup = None\n",
    "try:\n",
    "    p = paths[\"lookup\"]\n",
    "    if exists_nonempty(p):\n",
    "        lookup = pd.read_csv(p)\n",
    "        need_cols = {\"lab\", \"ADM2CD_c\", \"NAM_1\", \"NAM_2\"}\n",
    "        has_cols = need_cols.issubset(lookup.columns)\n",
    "        print(\"[Admin2 Lookup] columns:\", ok(has_cols), f\"shape={lookup.shape}\")\n",
    "        if has_cols:\n",
    "            is_unique = lookup[\"ADM2CD_c\"].is_unique\n",
    "            print(\"  unique ADM2CD_c:\", ok(is_unique))\n",
    "            if \"lab\" in lookup.columns:\n",
    "                expected_labs = list(range(1, len(lookup) + 1))\n",
    "                actual_labs = sorted(lookup[\"lab\"].tolist())\n",
    "                labs_sequential = (actual_labs == expected_labs)\n",
    "                print(\"  sequential lab:\", ok(labs_sequential))\n",
    "            if \"NAM_1\" in lookup.columns:\n",
    "                provinces = lookup[\"NAM_1\"].unique()\n",
    "                print(f\"  provinces: {', '.join(provinces)}\")\n",
    "            if \"NAM_2\" in lookup.columns:\n",
    "                n_municipalities = lookup[\"NAM_2\"].nunique()\n",
    "                print(f\"  municipalities: {n_municipalities}\")\n",
    "            print(lookup.head(3).to_string(index=False))\n",
    "    else:\n",
    "        print(\"[Admin2 Lookup] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Admin2 Lookup] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 11) Priority Admin2 Rank\n",
    "# ------------------------------\n",
    "admin2_rank = None\n",
    "try:\n",
    "    p = paths[\"admin2_rank\"]\n",
    "    if exists_nonempty(p):\n",
    "        admin2_rank = pd.read_csv(p)\n",
    "        need_cols = {\"ADM2CD_c\", \"NAM_1\", \"NAM_2\", \"score\", \"rank\", \"selected\", \"share_selected\"}\n",
    "        has_cols = need_cols.issubset(admin2_rank.columns)\n",
    "        print(\"[Priority Admin2 Rank] columns:\", ok(has_cols), f\"shape={admin2_rank.shape}\")\n",
    "        if has_cols:\n",
    "            if \"rank\" in admin2_rank.columns and admin2_rank[\"rank\"].notna().any():\n",
    "                rseq = sorted(admin2_rank[\"rank\"].dropna().astype(int))\n",
    "                contig = (rseq == list(range(min(rseq), max(rseq)+1)))\n",
    "                print(\"  contiguous ranks:\", ok(contig))\n",
    "                print(f\"  rank range: {min(rseq)} to {max(rseq)}\")\n",
    "            if \"score\" in admin2_rank.columns:\n",
    "                score_min = admin2_rank[\"score\"].min()\n",
    "                score_max = admin2_rank[\"score\"].max()\n",
    "                score_range_ok = (0 <= score_min <= 1) and (0 <= score_max <= 1)\n",
    "                print(\"  score range [0-1]:\", ok(score_range_ok), f\"[{score_min:.4f}, {score_max:.4f}]\")\n",
    "            if \"selected\" in admin2_rank.columns:\n",
    "                n_selected = admin2_rank[\"selected\"].sum()\n",
    "                pct_selected = (n_selected / len(admin2_rank)) * 100\n",
    "                print(f\"  selected municipalities: {n_selected}/{len(admin2_rank)} ({pct_selected:.1f}%)\")\n",
    "            if \"share_selected\" in admin2_rank.columns:\n",
    "                share_min = admin2_rank[\"share_selected\"].min()\n",
    "                share_max = admin2_rank[\"share_selected\"].max()\n",
    "                share_range_ok = (0 <= share_min <= 1) and (0 <= share_max <= 1)\n",
    "                print(\"  share_selected range [0-1]:\", ok(share_range_ok), f\"[{share_min:.4f}, {share_max:.4f}]\")\n",
    "            if \"rank\" in admin2_rank.columns:\n",
    "                top5 = admin2_rank.sort_values(\"rank\").head(5)\n",
    "                print(\"  Top 5 priority municipalities:\")\n",
    "                print(top5[[\"NAM_2\", \"score\", \"rank\", \"selected\"]].to_string(index=False))\n",
    "    else:\n",
    "        print(\"[Priority Admin2 Rank] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Priority Admin2 Rank] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 12) Priority clusters (schema-agnostic summary)\n",
    "# ------------------------------\n",
    "try:\n",
    "    p = paths[\"clusters\"]\n",
    "    if exists_nonempty(p):\n",
    "        cl = pd.read_csv(p)\n",
    "        print(\"[Priority clusters] present:\", ok(True), f\"shape={cl.shape}\")\n",
    "        # Try common fields if available\n",
    "        common = [c for c in [\"cluster_id\",\"cells\",\"km2\",\"score_mean\",\"selected\"] if c in cl.columns]\n",
    "        if common:\n",
    "            print(\"  sample cols:\", \", \".join(common))\n",
    "            print(cl[common].head(5).to_string(index=False))\n",
    "        else:\n",
    "            print(\"  columns:\", \", \".join(cl.columns[:12]), \"...\")\n",
    "    else:\n",
    "        print(\"[Priority clusters] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Priority clusters] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 13) Catchments KPIs\n",
    "# ------------------------------\n",
    "try:\n",
    "    if exists_nonempty(paths[\"catch_kpi\"]):\n",
    "        ck = pd.read_csv(paths[\"catch_kpi\"])\n",
    "        need = {\"site_index\",\"thresh_min\"}\n",
    "        print(\"[Catchments KPIs] columns:\", ok(need.issubset(ck.columns)), f\"shape={ck.shape}\")\n",
    "\n",
    "        # Types & ordering (robust to writer changes)\n",
    "        ck[\"thresh_min\"] = pd.to_numeric(ck[\"thresh_min\"], errors=\"coerce\")\n",
    "        if \"area_km2\" in ck.columns:\n",
    "            ck[\"area_km2\"] = pd.to_numeric(ck[\"area_km2\"], errors=\"coerce\")\n",
    "\n",
    "            ck_sorted = ck.sort_values([\"site_index\",\"thresh_min\"])\n",
    "\n",
    "            # Vectorized monotone check (no ambiguous truth values, no deprecation)\n",
    "            mono_series = (\n",
    "                ck_sorted\n",
    "                .groupby(\"site_index\", group_keys=False)[\"area_km2\"]\n",
    "                .apply(lambda s: (s.diff().fillna(0) >= -1e-6).all())\n",
    "            )\n",
    "            mono_pct = 100.0 * float(mono_series.mean()) if len(mono_series) else float(\"nan\")\n",
    "            print(f\"  monotone area by site: {ok(bool(mono_series.all()))} | {mono_pct:.0f}% sites OK\")\n",
    "        else:\n",
    "            print(\"  area_km2 missing → skip monotonicity\")\n",
    "    else:\n",
    "        print(\"[Catchments KPIs] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[Catchments KPIs] ERROR:\", e)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 14) Synergies (clusters & sites)\n",
    "# ------------------------------\n",
    "def _summarize_synergy(name, pth):\n",
    "    try:\n",
    "        if exists_nonempty(pth):\n",
    "            df = pd.read_csv(pth)\n",
    "            print(f\"[{name}] present:\", ok(True), f\"shape={df.shape}\")\n",
    "            # Try some common helpful summaries if columns exist\n",
    "            maybe_cols = set(df.columns.str.lower())\n",
    "            if {\"site_index\",\"cluster_id\"}.issubset(maybe_cols):\n",
    "                # group by cluster → count sites\n",
    "                si = [c for c in df.columns if c.lower()==\"site_index\"][0]\n",
    "                ci = [c for c in df.columns if c.lower()==\"cluster_id\"][0]\n",
    "                g = df.groupby(ci)[si].nunique().describe()[[\"count\",\"mean\",\"max\"]]\n",
    "                print(f\"  sites per cluster (count/mean/max): {g.to_dict()}\")\n",
    "            if {\"km2\",\"beneficiaries\"}.issubset(maybe_cols):\n",
    "                k2 = [c for c in df.columns if c.lower()==\"km2\"][0]\n",
    "                ben = [c for c in df.columns if c.lower()==\"beneficiaries\"][0]\n",
    "                print(f\"  totals → km2={df[k2].sum():.1f}, beneficiaries={int(df[ben].sum()):,}\")\n",
    "            print(\"  columns:\", \", \".join(df.columns[:12]), \"...\")\n",
    "        else:\n",
    "            print(f\"[{name}] MISSING or EMPTY\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{name}] ERROR:\", e)\n",
    "\n",
    "_summarize_synergy(\"Cluster synergies\", paths[\"clust_syn\"])\n",
    "_summarize_synergy(\"Site synergies\", paths[\"site_syn\"])\n",
    "\n",
    "# ------------------------------\n",
    "# 15) OD-Lite\n",
    "# ------------------------------\n",
    "try:\n",
    "    # Zone attributes\n",
    "    pz = paths[\"od_zone\"]\n",
    "    grav = paths[\"od_grav\"]\n",
    "    ag = paths[\"od_agents\"]\n",
    "\n",
    "    if exists_nonempty(pz):\n",
    "        Z = pd.read_csv(pz)\n",
    "        has_xy = {\"lon\",\"lat\"}.issubset(Z.columns)\n",
    "        has_id = any(c in Z.columns for c in [\"ADM2CD_c\",\"adm2cd_c\",\"id\",\"lab\"])\n",
    "        print(\"[OD zone attrs] has lon/lat:\", ok(has_xy), \"| has zone id:\", ok(has_id), f\"shape={Z.shape}\")\n",
    "    else:\n",
    "        Z = None\n",
    "        print(\"[OD zone attrs] MISSING or EMPTY\")\n",
    "\n",
    "    # Gravity table\n",
    "    if exists_nonempty(grav):\n",
    "        G = pd.read_csv(grav)\n",
    "        need = {\"oi\",\"dj\",\"flow\",\"dist_km\"}\n",
    "        print(\"[OD gravity] columns:\", ok(need.issubset(G.columns)), f\"rows={len(G)}\")\n",
    "        if need.issubset(G.columns):\n",
    "            # Basic validity: non-negative flows, diagonal allowed but distance should be ~0 there\n",
    "            nonneg = (G[\"flow\"] >= -1e-9).all()\n",
    "            print(\"  non-negative flows:\", ok(nonneg))\n",
    "            # Compute a couple of quick stats\n",
    "            total = G[\"flow\"].sum()\n",
    "            mean_d = np.average(G[\"dist_km\"], weights=G[\"flow\"]) if total > 0 else np.nan\n",
    "            print(f\"  total trips={total:,.0f} | flow-weighted mean dist={mean_d:,.1f} km\")\n",
    "            # Optional: check symmetry stats (not required for doubly-constrained but useful)\n",
    "            # Build small pivot if feasible\n",
    "            n_hint = int(np.sqrt(len(G)))\n",
    "            if n_hint <= 300:  # avoid huge pivots\n",
    "                piv = G.pivot_table(index=\"oi\", columns=\"dj\", values=\"flow\", aggfunc=\"sum\").fillna(0.0)\n",
    "                asym = np.abs(piv.values - piv.values.T).mean()\n",
    "                print(f\"  mean asymmetry |F - F^T| = {asym:,.2f}\")\n",
    "    else:\n",
    "        print(\"[OD gravity] MISSING or EMPTY\")\n",
    "\n",
    "    # Agents\n",
    "    if exists_nonempty(ag):\n",
    "        A = pd.read_csv(ag)\n",
    "        need = {\"oi\",\"dj\",\"o_lon\",\"o_lat\",\"d_lon\",\"d_lat\"}\n",
    "        print(\"[OD agents] columns:\", ok(need.issubset(A.columns)), f\"N={len(A)}\")\n",
    "        # Spot-check coordinates in plausible bounds\n",
    "        for k in [\"o_lon\",\"d_lon\"]:\n",
    "            if k in A:\n",
    "                in_lon = A[k].between(-180, 180).mean()\n",
    "                print(f\"  {k} in [-180,180]: {in_lon:.2%}\")\n",
    "        for k in [\"o_lat\",\"d_lat\"]:\n",
    "            if k in A:\n",
    "                in_lat = A[k].between(-90, 90).mean()\n",
    "                print(f\"  {k} in [-90,90]: {in_lat:.2%}\")\n",
    "    else:\n",
    "        print(\"[OD agents] MISSING or EMPTY\")\n",
    "except Exception as e:\n",
    "    print(\"[OD] ERROR:\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 16) CROSS-FILE VALIDATION\n",
    "# ------------------------------\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CROSS-FILE VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # Lookup ↔ Admin2 Rank\n",
    "    if paths[\"lookup\"].exists() and paths[\"admin2_rank\"].exists():\n",
    "        lookup = pd.read_csv(paths[\"lookup\"])\n",
    "        admin2_rank = pd.read_csv(paths[\"admin2_rank\"])\n",
    "        lookup_codes = set(lookup.get(\"ADM2CD_c\", pd.Series(dtype=str)))\n",
    "        rank_codes = set(admin2_rank.get(\"ADM2CD_c\", pd.Series(dtype=str)))\n",
    "        codes_match = (lookup_codes == rank_codes)\n",
    "        print(\"[Lookup ↔ Admin2 Rank] ADM2CD_c match:\", ok(codes_match))\n",
    "        if not codes_match:\n",
    "            missing_in_rank = sorted(list(lookup_codes - rank_codes))[:10]\n",
    "            missing_in_lookup = sorted(list(rank_codes - lookup_codes))[:10]\n",
    "            if missing_in_rank:\n",
    "                print(f\"  Missing in rank (first 10): {missing_in_rank}\")\n",
    "            if missing_in_lookup:\n",
    "                print(f\"  Missing in lookup (first 10): {missing_in_lookup}\")\n",
    "\n",
    "    # Lookup ↔ Muni Indicators count\n",
    "    if paths[\"lookup\"].exists() and paths[\"muni\"].exists():\n",
    "        lookup = pd.read_csv(paths[\"lookup\"])\n",
    "        muni = pd.read_csv(paths[\"muni\"])\n",
    "        n_lookup = len(lookup)\n",
    "        n_muni_unique = len(muni[[\"ADM2CD_c\"]].drop_duplicates()) if \"ADM2CD_c\" in muni.columns else None\n",
    "        count_match = (n_muni_unique == n_lookup) if n_muni_unique is not None else False\n",
    "        print(\"[Lookup ↔ Muni Indicators] count match:\", ok(count_match),\n",
    "              f\"lookup={n_lookup} muni_unique={n_muni_unique}\")\n",
    "\n",
    "    # Admin2 Rank ↔ Muni shortlist: same ADM2 universe\n",
    "    if admin2_rank is not None and exists_nonempty(paths[\"rank\"]):\n",
    "        muni_rank = pd.read_csv(paths[\"rank\"])\n",
    "        if \"ADM2CD_c\" in admin2_rank.columns and \"ADM2CD_c\" in muni_rank.columns:\n",
    "            codes_a = set(admin2_rank[\"ADM2CD_c\"])\n",
    "            codes_m = set(muni_rank[\"ADM2CD_c\"])\n",
    "            codes_match = (codes_a == codes_m)\n",
    "            print(\"[Admin2 Rank ↔ Muni shortlist] ADM2CD_c match:\", ok(codes_match))\n",
    "            if not codes_match:\n",
    "                missing_in_m = sorted(list(codes_a - codes_m))[:10]\n",
    "                missing_in_a = sorted(list(codes_m - codes_a))[:10]\n",
    "                if missing_in_m:\n",
    "                    print(\"  In admin2_rank but not muni_rank (first 10):\", missing_in_m)\n",
    "                if missing_in_a:\n",
    "                    print(\"  In muni_rank but not admin2_rank (first 10):\", missing_in_a)\n",
    "\n",
    "    # OD zones ↔ lookup (count consistency if both exist)\n",
    "    if paths[\"od_zone\"].exists() and paths[\"lookup\"].exists():\n",
    "        Z = pd.read_csv(paths[\"od_zone\"])\n",
    "        L = pd.read_csv(paths[\"lookup\"])\n",
    "        # Try to infer the ID column in Z\n",
    "        z_id = None\n",
    "        for cand in [\"ADM2CD_c\",\"adm2cd_c\",\"lab\",\"id\"]:\n",
    "            if cand in Z.columns:\n",
    "                z_id = cand\n",
    "                break\n",
    "        if z_id is not None:\n",
    "            n_match = len(set(Z[z_id])) == len(L)\n",
    "            print(\"[OD zones ↔ Lookup] zone count matches:\", ok(n_match), f\"zones={len(Z)} lookup={len(L)}\")\n",
    "        else:\n",
    "            print(\"[OD zones ↔ Lookup] SKIP (no recognizable zone id column)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"[Cross-validation] ERROR:\", e)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VALIDATION COMPLETE\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9fd1a-da92-4d80-b083-e00fc5472da5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
