{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68100441-e62e-4564-af4c-c0499a45d74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Data Processing Script\n",
      "==================================================\n",
      "\n",
      "Listing CSV files in: /mnt/d/temp/gost_map_template/layers/request/shiny\n",
      "==================================================\n",
      "Base files:\n",
      "  - adm2.csv\n",
      "  - base.csv\n",
      "\n",
      "Map data files by theme:\n",
      "  communications: 6 files\n",
      "  hydric: 5 files\n",
      "  infra: 10 files\n",
      "  insecurity: 9 files\n",
      "  outflow: 7 files\n",
      "  poverty: 3 files\n",
      "    - map_poverty_data1.csv\n",
      "    - map_poverty_data2.csv\n",
      "    - map_poverty_data3.csv\n",
      "  production: 10 files\n",
      "  ttvma: 1 files\n",
      "    - map_ttvma_data1.csv\n",
      "\n",
      "Total: 82 CSV files\n",
      "\n",
      "==================================================\n",
      "FILE STRUCTURE INSPECTION\n",
      "==================================================\n",
      "\n",
      "Inspecting base.csv:\n",
      "    Detected delimiter: semicolon\n",
      "  Columns found: ['adm2code', 'muni_n_af']\n",
      "  Shape: 160 rows × 2 columns\n",
      "  First row sample:\n",
      "    {'adm2code': 'AGO019001', 'muni_n_af': 'Alto Zambeze'}\n",
      "\n",
      "Inspecting adm2.csv:\n",
      "    Detected delimiter: semicolon\n",
      "  Columns found: ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code']\n",
      "  Shape: 164 rows × 6 columns\n",
      "  First row sample:\n",
      "    {'iso3': 'AGO', 'adm0name': 'Angola', 'adm1name': 'Uíge', 'adm1code': 'AGO017', 'adm2name': 'Alto Cauale', 'adm2code': 'AGO017001'}\n",
      "\n",
      "Inspecting map_cdd_data (1).csv:\n",
      "    Detected delimiter: comma\n",
      "  Columns found: ['muni_n_af', 'period', 'indicator', 'change', 'scenario', 'output', 'change_cat']\n",
      "  Shape: 161 rows × 7 columns\n",
      "  First row sample:\n",
      "    {'muni_n_af': 'Alto Zambeze', 'period': '2020-2039', 'indicator': 'cdd_85_y1980', 'change': 9.5, 'scenario': '2. Emissões Elevadas', 'output': 'Dias Secos Consecutivos', 'change_cat': '[-7.92,10.3]'}\n",
      "\n",
      "==================================================\n",
      "Validating input files...\n",
      "    Detected delimiter: semicolon\n",
      "  ✓ base.csv validated (160 rows)\n",
      "    Detected delimiter: semicolon\n",
      "  ✓ adm2.csv validated (164 rows)\n",
      "    Detected delimiter: comma\n",
      "    Detected delimiter: comma\n",
      "    Detected delimiter: comma\n",
      "    Detected delimiter: comma\n",
      "    Detected delimiter: comma\n",
      "    Detected delimiter: comma\n",
      "    Detected delimiter: comma\n",
      "  ✓ Map files found:\n",
      "      communications: 6 files\n",
      "      hydric: 5 files\n",
      "      infra: 10 files\n",
      "      insecurity: 9 files\n",
      "      outflow: 7 files\n",
      "      poverty: 3 files\n",
      "      production: 10 files\n",
      "\n",
      "✓ All validations passed!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to proceed with processing? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting processing...\n",
      "Working directory: /mnt/d/temp/gost_map_template/layers/request/shiny\n",
      "\n",
      "Loading base.csv...\n",
      "    Detected delimiter: semicolon\n",
      "  Base data loaded: 160 rows\n",
      "  Columns: ['adm2code', 'muni_n_af']\n",
      "\n",
      "Loading adm2.csv...\n",
      "    Detected delimiter: semicolon\n",
      "  ADM2 data loaded: 164 rows\n",
      "  Columns: ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code']\n",
      "\n",
      "==================================================\n",
      "Processing theme: communications\n",
      "==================================================\n",
      "  Found 6 files for communications:\n",
      "    - map_communications_data1.csv\n",
      "    - map_communications_data2.csv\n",
      "    - map_communications_data3.csv\n",
      "    - map_communications_data4.csv\n",
      "    - map_communications_data5.csv\n",
      "    - map_communications_data6.csv\n",
      "\n",
      "  Processing map_communications_data1.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data1'], rows = 160\n",
      "\n",
      "  Processing map_communications_data2.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data2'], rows = 160\n",
      "\n",
      "  Processing map_communications_data3.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data3'], rows = 160\n",
      "\n",
      "  Processing map_communications_data4.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data4'], rows = 160\n",
      "\n",
      "  Processing map_communications_data5.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data5'], rows = 160\n",
      "\n",
      "  Processing map_communications_data6.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data6'], rows = 160\n",
      "\n",
      "  Combining all communications files...\n",
      "    Joining data1...\n",
      "    Joining data2...\n",
      "    Joining data3...\n",
      "    Joining data4...\n",
      "    Joining data5...\n",
      "    Joining data6...\n",
      "\n",
      "  ✓ Saved ago_tbl_communications_rapp_2020.csv\n",
      "    Location: /mnt/d/temp/gost_map_template/layers/request/shiny/ago_tbl_communications_rapp_2020.csv\n",
      "    Final shape: 164 rows × 12 columns\n",
      "    Columns: ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6']\n",
      "    Data columns summary:\n",
      "      data1: 160 non-null values\n",
      "      data2: 160 non-null values\n",
      "      data3: 160 non-null values\n",
      "      data4: 160 non-null values\n",
      "      data5: 160 non-null values\n",
      "      data6: 160 non-null values\n",
      "\n",
      "==================================================\n",
      "Processing theme: hydric\n",
      "==================================================\n",
      "  Found 5 files for hydric:\n",
      "    - map_hydric_data1.csv\n",
      "    - map_hydric_data2.csv\n",
      "    - map_hydric_data3.csv\n",
      "    - map_hydric_data4.csv\n",
      "    - map_hydric_data5.csv\n",
      "\n",
      "  Processing map_hydric_data1.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data1'], rows = 160\n",
      "\n",
      "  Processing map_hydric_data2.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data2'], rows = 160\n",
      "\n",
      "  Processing map_hydric_data3.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data3'], rows = 160\n",
      "\n",
      "  Processing map_hydric_data4.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data4'], rows = 160\n",
      "\n",
      "  Processing map_hydric_data5.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data5'], rows = 160\n",
      "\n",
      "  Combining all hydric files...\n",
      "    Joining data1...\n",
      "    Joining data2...\n",
      "    Joining data3...\n",
      "    Joining data4...\n",
      "    Joining data5...\n",
      "\n",
      "  ✓ Saved ago_tbl_hydric_rapp_2020.csv\n",
      "    Location: /mnt/d/temp/gost_map_template/layers/request/shiny/ago_tbl_hydric_rapp_2020.csv\n",
      "    Final shape: 164 rows × 11 columns\n",
      "    Columns: ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code', 'data1', 'data2', 'data3', 'data4', 'data5']\n",
      "    Data columns summary:\n",
      "      data1: 160 non-null values\n",
      "      data2: 160 non-null values\n",
      "      data3: 160 non-null values\n",
      "      data4: 160 non-null values\n",
      "      data5: 160 non-null values\n",
      "\n",
      "==================================================\n",
      "Processing theme: infra\n",
      "==================================================\n",
      "  Found 10 files for infra:\n",
      "    - map_infra_data1.csv\n",
      "    - map_infra_data2.csv\n",
      "    - map_infra_data3.csv\n",
      "    - map_infra_data4.csv\n",
      "    - map_infra_data5.csv\n",
      "    - map_infra_data6.csv\n",
      "    - map_infra_data7.csv\n",
      "    - map_infra_data8.csv\n",
      "    - map_infra_data9.csv\n",
      "    - map_infra_data10.csv\n",
      "\n",
      "  Processing map_infra_data1.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data1'], rows = 160\n",
      "\n",
      "  Processing map_infra_data2.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data2'], rows = 160\n",
      "\n",
      "  Processing map_infra_data3.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data3'], rows = 160\n",
      "\n",
      "  Processing map_infra_data4.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data4'], rows = 160\n",
      "\n",
      "  Processing map_infra_data5.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data5'], rows = 160\n",
      "\n",
      "  Processing map_infra_data6.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data6'], rows = 160\n",
      "\n",
      "  Processing map_infra_data7.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data7'], rows = 160\n",
      "\n",
      "  Processing map_infra_data8.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data8'], rows = 160\n",
      "\n",
      "  Processing map_infra_data9.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data9'], rows = 160\n",
      "\n",
      "  Processing map_infra_data10.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data10'], rows = 160\n",
      "\n",
      "  Combining all infra files...\n",
      "    Joining data1...\n",
      "    Joining data2...\n",
      "    Joining data3...\n",
      "    Joining data4...\n",
      "    Joining data5...\n",
      "    Joining data6...\n",
      "    Joining data7...\n",
      "    Joining data8...\n",
      "    Joining data9...\n",
      "    Joining data10...\n",
      "\n",
      "  ✓ Saved ago_tbl_infra_rapp_2020.csv\n",
      "    Location: /mnt/d/temp/gost_map_template/layers/request/shiny/ago_tbl_infra_rapp_2020.csv\n",
      "    Final shape: 164 rows × 16 columns\n",
      "    Columns: ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8', 'data9', 'data10']\n",
      "    Data columns summary:\n",
      "      data1: 160 non-null values\n",
      "      data2: 160 non-null values\n",
      "      data3: 160 non-null values\n",
      "      data4: 160 non-null values\n",
      "      data5: 160 non-null values\n",
      "      data6: 160 non-null values\n",
      "      data7: 160 non-null values\n",
      "      data8: 160 non-null values\n",
      "      data9: 160 non-null values\n",
      "      data10: 160 non-null values\n",
      "\n",
      "==================================================\n",
      "Processing theme: insecurity\n",
      "==================================================\n",
      "  Found 9 files for insecurity:\n",
      "    - map_insecurity_data1.csv\n",
      "    - map_insecurity_data2.csv\n",
      "    - map_insecurity_data3.csv\n",
      "    - map_insecurity_data4.csv\n",
      "    - map_insecurity_data5.csv\n",
      "    - map_insecurity_data6.csv\n",
      "    - map_insecurity_data7.csv\n",
      "    - map_insecurity_data8.csv\n",
      "    - map_insecurity_data9.csv\n",
      "\n",
      "  Processing map_insecurity_data1.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data1'], rows = 160\n",
      "\n",
      "  Processing map_insecurity_data2.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data2'], rows = 160\n",
      "\n",
      "  Processing map_insecurity_data3.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data3'], rows = 160\n",
      "\n",
      "  Processing map_insecurity_data4.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data4'], rows = 160\n",
      "\n",
      "  Processing map_insecurity_data5.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data5'], rows = 160\n",
      "\n",
      "  Processing map_insecurity_data6.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data6'], rows = 160\n",
      "\n",
      "  Processing map_insecurity_data7.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data7'], rows = 160\n",
      "\n",
      "  Processing map_insecurity_data8.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data8'], rows = 160\n",
      "\n",
      "  Processing map_insecurity_data9.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data9'], rows = 160\n",
      "\n",
      "  Combining all insecurity files...\n",
      "    Joining data1...\n",
      "    Joining data2...\n",
      "    Joining data3...\n",
      "    Joining data4...\n",
      "    Joining data5...\n",
      "    Joining data6...\n",
      "    Joining data7...\n",
      "    Joining data8...\n",
      "    Joining data9...\n",
      "\n",
      "  ✓ Saved ago_tbl_insecurity_rapp_2020.csv\n",
      "    Location: /mnt/d/temp/gost_map_template/layers/request/shiny/ago_tbl_insecurity_rapp_2020.csv\n",
      "    Final shape: 164 rows × 15 columns\n",
      "    Columns: ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8', 'data9']\n",
      "    Data columns summary:\n",
      "      data1: 160 non-null values\n",
      "      data2: 160 non-null values\n",
      "      data3: 160 non-null values\n",
      "      data4: 160 non-null values\n",
      "      data5: 160 non-null values\n",
      "      data6: 160 non-null values\n",
      "      data7: 160 non-null values\n",
      "      data8: 160 non-null values\n",
      "      data9: 160 non-null values\n",
      "\n",
      "==================================================\n",
      "Processing theme: outflow\n",
      "==================================================\n",
      "  Found 7 files for outflow:\n",
      "    - map_outflow_data1.csv\n",
      "    - map_outflow_data2.csv\n",
      "    - map_outflow_data3.csv\n",
      "    - map_outflow_data4.csv\n",
      "    - map_outflow_data5.csv\n",
      "    - map_outflow_data6.csv\n",
      "    - map_outflow_data7.csv\n",
      "\n",
      "  Processing map_outflow_data1.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data1'], rows = 160\n",
      "\n",
      "  Processing map_outflow_data2.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data2'], rows = 160\n",
      "\n",
      "  Processing map_outflow_data3.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data3'], rows = 160\n",
      "\n",
      "  Processing map_outflow_data4.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data4'], rows = 160\n",
      "\n",
      "  Processing map_outflow_data5.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data5'], rows = 160\n",
      "\n",
      "  Processing map_outflow_data6.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data6'], rows = 160\n",
      "\n",
      "  Processing map_outflow_data7.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data7'], rows = 160\n",
      "\n",
      "  Combining all outflow files...\n",
      "    Joining data1...\n",
      "    Joining data2...\n",
      "    Joining data3...\n",
      "    Joining data4...\n",
      "    Joining data5...\n",
      "    Joining data6...\n",
      "    Joining data7...\n",
      "\n",
      "  ✓ Saved ago_tbl_outflow_rapp_2020.csv\n",
      "    Location: /mnt/d/temp/gost_map_template/layers/request/shiny/ago_tbl_outflow_rapp_2020.csv\n",
      "    Final shape: 164 rows × 13 columns\n",
      "    Columns: ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7']\n",
      "    Data columns summary:\n",
      "      data1: 160 non-null values\n",
      "      data2: 160 non-null values\n",
      "      data3: 160 non-null values\n",
      "      data4: 160 non-null values\n",
      "      data5: 160 non-null values\n",
      "      data6: 160 non-null values\n",
      "      data7: 160 non-null values\n",
      "\n",
      "==================================================\n",
      "Processing theme: poverty\n",
      "==================================================\n",
      "  Found 3 files for poverty:\n",
      "    - map_poverty_data1.csv\n",
      "    - map_poverty_data2.csv\n",
      "    - map_poverty_data3.csv\n",
      "\n",
      "  Processing map_poverty_data1.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data1'], rows = 160\n",
      "\n",
      "  Processing map_poverty_data2.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 142 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 144 rows\n",
      "    Processed: columns = ['adm2code', 'data2'], rows = 142\n",
      "\n",
      "  Processing map_poverty_data3.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data3'], rows = 160\n",
      "\n",
      "  Combining all poverty files...\n",
      "    Joining data1...\n",
      "    Joining data2...\n",
      "    Joining data3...\n",
      "\n",
      "  ✓ Saved ago_tbl_poverty_rapp_2020.csv\n",
      "    Location: /mnt/d/temp/gost_map_template/layers/request/shiny/ago_tbl_poverty_rapp_2020.csv\n",
      "    Final shape: 164 rows × 9 columns\n",
      "    Columns: ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code', 'data1', 'data2', 'data3']\n",
      "    Data columns summary:\n",
      "      data1: 160 non-null values\n",
      "      data2: 142 non-null values\n",
      "      data3: 160 non-null values\n",
      "\n",
      "==================================================\n",
      "Processing theme: production\n",
      "==================================================\n",
      "  Found 10 files for production:\n",
      "    - map_production_data1.csv\n",
      "    - map_production_data2.csv\n",
      "    - map_production_data3.csv\n",
      "    - map_production_data4.csv\n",
      "    - map_production_data5.csv\n",
      "    - map_production_data6.csv\n",
      "    - map_production_data7.csv\n",
      "    - map_production_data8.csv\n",
      "    - map_production_data9.csv\n",
      "    - map_production_data10.csv\n",
      "\n",
      "  Processing map_production_data1.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data1'], rows = 160\n",
      "\n",
      "  Processing map_production_data2.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data2'], rows = 160\n",
      "\n",
      "  Processing map_production_data3.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data3'], rows = 160\n",
      "\n",
      "  Processing map_production_data4.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data4'], rows = 160\n",
      "\n",
      "  Processing map_production_data5.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data5'], rows = 160\n",
      "\n",
      "  Processing map_production_data6.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data6'], rows = 160\n",
      "\n",
      "  Processing map_production_data7.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data7'], rows = 160\n",
      "\n",
      "  Processing map_production_data8.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data8'], rows = 160\n",
      "\n",
      "  Processing map_production_data9.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data9'], rows = 160\n",
      "\n",
      "  Processing map_production_data10.csv...\n",
      "    Detected delimiter: comma\n",
      "    Loaded: 160 rows\n",
      "    Columns: ['muni_n_af', 'variable', 'value']\n",
      "    After joining with base: 162 rows\n",
      "    Processed: columns = ['adm2code', 'data10'], rows = 160\n",
      "\n",
      "  Combining all production files...\n",
      "    Joining data1...\n",
      "    Joining data2...\n",
      "    Joining data3...\n",
      "    Joining data4...\n",
      "    Joining data5...\n",
      "    Joining data6...\n",
      "    Joining data7...\n",
      "    Joining data8...\n",
      "    Joining data9...\n",
      "    Joining data10...\n",
      "\n",
      "  ✓ Saved ago_tbl_production_rapp_2020.csv\n",
      "    Location: /mnt/d/temp/gost_map_template/layers/request/shiny/ago_tbl_production_rapp_2020.csv\n",
      "    Final shape: 164 rows × 16 columns\n",
      "    Columns: ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8', 'data9', 'data10']\n",
      "    Data columns summary:\n",
      "      data1: 160 non-null values\n",
      "      data2: 160 non-null values\n",
      "      data3: 160 non-null values\n",
      "      data4: 160 non-null values\n",
      "      data5: 160 non-null values\n",
      "      data6: 160 non-null values\n",
      "      data7: 160 non-null values\n",
      "      data8: 160 non-null values\n",
      "      data9: 160 non-null values\n",
      "      data10: 160 non-null values\n",
      "\n",
      "==================================================\n",
      "Processing complete!\n",
      "Output files saved in: /mnt/d/temp/gost_map_template/layers/request/shiny\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "# Configuration - Update this path as needed\n",
    "DATA_PATH = \"/mnt/d/temp/gost_map_template/layers/request/shiny\"\n",
    "\n",
    "# Alternative Windows path (uncomment if using Windows directly)\n",
    "# DATA_PATH = r\"D:\\temp\\gost_map_template\\layers\\request\\shiny\"\n",
    "\n",
    "def detect_delimiter(file_path, num_lines=5):\n",
    "    \"\"\"\n",
    "    Detect the delimiter used in a CSV file by examining the first few lines.\n",
    "    \"\"\"\n",
    "    delimiters = [',', ';', '\\t', '|']\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            # Read first few lines\n",
    "            lines = []\n",
    "            for _ in range(num_lines):\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                lines.append(line)\n",
    "            \n",
    "            if not lines:\n",
    "                return ','  # Default to comma if file is empty\n",
    "            \n",
    "            # Count occurrences of each delimiter\n",
    "            delimiter_counts = {}\n",
    "            for delim in delimiters:\n",
    "                counts = [line.count(delim) for line in lines]\n",
    "                # Check if delimiter appears consistently\n",
    "                if all(c > 0 for c in counts) and len(set(counts)) == 1:\n",
    "                    delimiter_counts[delim] = counts[0]\n",
    "            \n",
    "            # Return delimiter with highest consistent count\n",
    "            if delimiter_counts:\n",
    "                return max(delimiter_counts, key=delimiter_counts.get)\n",
    "            \n",
    "            # Try csv.Sniffer as fallback\n",
    "            file.seek(0)\n",
    "            sample = file.read(1024)\n",
    "            sniffer = csv.Sniffer()\n",
    "            delimiter = sniffer.sniff(sample).delimiter\n",
    "            return delimiter\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    Warning: Could not detect delimiter: {e}\")\n",
    "        return ','  # Default to comma\n",
    "\n",
    "def read_csv_auto(file_path):\n",
    "    \"\"\"\n",
    "    Read a CSV file with automatic delimiter detection.\n",
    "    \"\"\"\n",
    "    delimiter = detect_delimiter(file_path)\n",
    "    delimiter_name = {',': 'comma', ';': 'semicolon', '\\t': 'tab', '|': 'pipe'}.get(delimiter, delimiter)\n",
    "    print(f\"    Detected delimiter: {delimiter_name}\")\n",
    "    \n",
    "    try:\n",
    "        # Try reading with detected delimiter\n",
    "        df = pd.read_csv(file_path, delimiter=delimiter, encoding='utf-8')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"    Error with utf-8, trying latin-1 encoding...\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter=delimiter, encoding='latin-1')\n",
    "            return df\n",
    "        except Exception as e2:\n",
    "            print(f\"    Error reading file: {e2}\")\n",
    "            return None\n",
    "\n",
    "def inspect_file(file_path, file_name=\"file\"):\n",
    "    \"\"\"\n",
    "    Inspect a CSV file and show its structure.\n",
    "    \"\"\"\n",
    "    print(f\"\\nInspecting {file_name}:\")\n",
    "    df = read_csv_auto(file_path)\n",
    "    if df is not None:\n",
    "        print(f\"  Columns found: {list(df.columns)}\")\n",
    "        print(f\"  Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "        print(f\"  First row sample:\")\n",
    "        if len(df) > 0:\n",
    "            print(f\"    {df.iloc[0].to_dict()}\")\n",
    "    return df\n",
    "\n",
    "def process_csv_files():\n",
    "    \"\"\"\n",
    "    Main function to process CSV files according to specifications:\n",
    "    1. Join base.csv with map_{theme}_data{num}.csv files\n",
    "    2. Transform columns (drop muni_n_af, variable; rename value)\n",
    "    3. Join by theme with adm2.csv and save final results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define themes\n",
    "    themes = ['communications', 'hydric', 'infra', 'insecurity', \n",
    "              'outflow', 'poverty', 'production']\n",
    "    \n",
    "    # Set working directory or use full paths\n",
    "    base_path = Path(DATA_PATH)\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not base_path.exists():\n",
    "        print(f\"Error: Directory not found: {DATA_PATH}\")\n",
    "        print(\"Please check the path and update DATA_PATH variable in the script.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Working directory: {base_path}\")\n",
    "    \n",
    "    # File paths\n",
    "    base_file = base_path / 'base.csv'\n",
    "    adm2_file = base_path / 'adm2.csv'\n",
    "    \n",
    "    # Check if required base files exist\n",
    "    if not base_file.exists():\n",
    "        print(f\"Error: base.csv not found at {base_file}\")\n",
    "        return\n",
    "    \n",
    "    if not adm2_file.exists():\n",
    "        print(f\"Error: adm2.csv not found at {adm2_file}\")\n",
    "        return\n",
    "    \n",
    "    # Load base files with auto-detection\n",
    "    print(\"\\nLoading base.csv...\")\n",
    "    base_df = read_csv_auto(base_file)\n",
    "    if base_df is None:\n",
    "        print(\"Error: Could not read base.csv\")\n",
    "        return\n",
    "    print(f\"  Base data loaded: {len(base_df)} rows\")\n",
    "    print(f\"  Columns: {list(base_df.columns)}\")\n",
    "    \n",
    "    print(\"\\nLoading adm2.csv...\")\n",
    "    adm2_df = read_csv_auto(adm2_file)\n",
    "    if adm2_df is None:\n",
    "        print(\"Error: Could not read adm2.csv\")\n",
    "        return\n",
    "    print(f\"  ADM2 data loaded: {len(adm2_df)} rows\")\n",
    "    print(f\"  Columns: {list(adm2_df.columns)}\")\n",
    "    \n",
    "    # Process each theme\n",
    "    for theme in themes:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing theme: {theme}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        # Find all CSV files for this theme\n",
    "        pattern = f'map_{theme}_data*.csv'\n",
    "        theme_files = list(base_path.glob(pattern))\n",
    "        \n",
    "        if not theme_files:\n",
    "            print(f\"  No files found for pattern: {pattern}\")\n",
    "            continue\n",
    "        \n",
    "        # Sort files to ensure correct order (data1, data2, ..., data10)\n",
    "        theme_files = sorted(theme_files, key=lambda x: int(re.search(r'data(\\d+)', x.name).group(1)))\n",
    "        \n",
    "        print(f\"  Found {len(theme_files)} files for {theme}:\")\n",
    "        for file in theme_files:\n",
    "            print(f\"    - {file.name}\")\n",
    "        \n",
    "        # Dictionary to store processed dataframes for this theme\n",
    "        theme_dfs = {}\n",
    "        \n",
    "        # Step 1 & 2: Process each file\n",
    "        for file_path in theme_files:\n",
    "            # Extract the number from filename\n",
    "            match = re.search(r'data(\\d+)', file_path.name)\n",
    "            if not match:\n",
    "                print(f\"  Warning: Could not extract number from {file_path.name}\")\n",
    "                continue\n",
    "            \n",
    "            num = match.group(1)\n",
    "            \n",
    "            print(f\"\\n  Processing {file_path.name}...\")\n",
    "            \n",
    "            # Read the map file with auto-detection\n",
    "            map_df = read_csv_auto(file_path)\n",
    "            if map_df is None:\n",
    "                print(f\"    Error: Could not read {file_path.name}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"    Loaded: {len(map_df)} rows\")\n",
    "            print(f\"    Columns: {list(map_df.columns)}\")\n",
    "            \n",
    "            # Check if required columns exist\n",
    "            required_cols = ['muni_n_af', 'variable', 'value']\n",
    "            if not all(col in map_df.columns for col in required_cols):\n",
    "                print(f\"    Warning: Missing required columns. Found: {list(map_df.columns)}\")\n",
    "                continue\n",
    "            \n",
    "            # Step 1: Join with base.csv on muni_n_af\n",
    "            merged_df = pd.merge(base_df, map_df, on='muni_n_af', how='inner')\n",
    "            print(f\"    After joining with base: {len(merged_df)} rows\")\n",
    "            \n",
    "            if len(merged_df) == 0:\n",
    "                print(f\"    Warning: No matching records found when joining with base.csv\")\n",
    "                continue\n",
    "            \n",
    "            # Step 2: Drop muni_n_af and variable columns, rename value column\n",
    "            processed_df = merged_df[['adm2code', 'value']].copy()\n",
    "            processed_df = processed_df.rename(columns={'value': f'data{num}'})\n",
    "            \n",
    "            # Remove duplicates if any (keep first occurrence)\n",
    "            processed_df = processed_df.drop_duplicates(subset=['adm2code'], keep='first')\n",
    "            \n",
    "            # Store the processed dataframe\n",
    "            theme_dfs[int(num)] = processed_df\n",
    "            print(f\"    Processed: columns = {list(processed_df.columns)}, rows = {len(processed_df)}\")\n",
    "        \n",
    "        if not theme_dfs:\n",
    "            print(f\"  No valid data files processed for {theme}\")\n",
    "            continue\n",
    "        \n",
    "        # Step 3: Join all processed files for this theme\n",
    "        print(f\"\\n  Combining all {theme} files...\")\n",
    "        \n",
    "        # Start with adm2.csv as the base\n",
    "        final_df = adm2_df.copy()\n",
    "        \n",
    "        # Join each processed file in order\n",
    "        for num in sorted(theme_dfs.keys()):\n",
    "            df = theme_dfs[num]\n",
    "            print(f\"    Joining data{num}...\")\n",
    "            \n",
    "            # Perform left join to keep all adm2 records\n",
    "            final_df = pd.merge(final_df, df, on='adm2code', how='left')\n",
    "        \n",
    "        # Save the final result in the same directory\n",
    "        output_filename = f'ago_tbl_{theme}_rapp_2020.csv'\n",
    "        output_path = base_path / output_filename\n",
    "        final_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"\\n  ✓ Saved {output_filename}\")\n",
    "        print(f\"    Location: {output_path}\")\n",
    "        print(f\"    Final shape: {final_df.shape[0]} rows × {final_df.shape[1]} columns\")\n",
    "        print(f\"    Columns: {list(final_df.columns)}\")\n",
    "        \n",
    "        # Display summary statistics\n",
    "        data_cols = [col for col in final_df.columns if col.startswith('data')]\n",
    "        if data_cols:\n",
    "            print(f\"    Data columns summary:\")\n",
    "            for col in data_cols:\n",
    "                non_null = final_df[col].notna().sum()\n",
    "                print(f\"      {col}: {non_null} non-null values\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Processing complete!\")\n",
    "    print(f\"Output files saved in: {base_path}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "def validate_input_files():\n",
    "    \"\"\"\n",
    "    Validate that all required input files exist and have correct structure\n",
    "    \"\"\"\n",
    "    print(\"Validating input files...\")\n",
    "    \n",
    "    base_path = Path(DATA_PATH)\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not base_path.exists():\n",
    "        print(f\"❌ Directory not found: {DATA_PATH}\")\n",
    "        return False\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    # Check base.csv\n",
    "    base_file = base_path / 'base.csv'\n",
    "    if base_file.exists():\n",
    "        df = read_csv_auto(base_file)\n",
    "        if df is not None:\n",
    "            required_cols = ['adm2code', 'muni_n_af']\n",
    "            missing = [col for col in required_cols if col not in df.columns]\n",
    "            if missing:\n",
    "                issues.append(f\"base.csv missing columns: {missing}. Found: {list(df.columns)}\")\n",
    "            else:\n",
    "                print(f\"  ✓ base.csv validated ({len(df)} rows)\")\n",
    "        else:\n",
    "            issues.append(\"base.csv could not be read\")\n",
    "    else:\n",
    "        issues.append(\"base.csv not found\")\n",
    "    \n",
    "    # Check adm2.csv\n",
    "    adm2_file = base_path / 'adm2.csv'\n",
    "    if adm2_file.exists():\n",
    "        df = read_csv_auto(adm2_file)\n",
    "        if df is not None:\n",
    "            required_cols = ['iso3', 'adm0name', 'adm1name', 'adm1code', 'adm2name', 'adm2code']\n",
    "            missing = [col for col in required_cols if col not in df.columns]\n",
    "            if missing:\n",
    "                issues.append(f\"adm2.csv missing columns: {missing}. Found: {list(df.columns)}\")\n",
    "            else:\n",
    "                print(f\"  ✓ adm2.csv validated ({len(df)} rows)\")\n",
    "        else:\n",
    "            issues.append(\"adm2.csv could not be read\")\n",
    "    else:\n",
    "        issues.append(\"adm2.csv not found\")\n",
    "    \n",
    "    # Check for map files\n",
    "    themes = ['communications', 'hydric', 'infra', 'insecurity', \n",
    "              'outflow', 'poverty', 'production']\n",
    "    \n",
    "    map_files_summary = {}\n",
    "    for theme in themes:\n",
    "        pattern = f'map_{theme}_data*.csv'\n",
    "        files = list(base_path.glob(pattern))\n",
    "        if files:\n",
    "            map_files_summary[theme] = len(files)\n",
    "            # Check structure of first file\n",
    "            df = read_csv_auto(files[0])\n",
    "            if df is not None:\n",
    "                required_cols = ['muni_n_af', 'variable', 'value']\n",
    "                missing = [col for col in required_cols if col not in df.columns]\n",
    "                if missing:\n",
    "                    issues.append(f\"{files[0].name} missing columns: {missing}. Found: {list(df.columns)}\")\n",
    "    \n",
    "    if map_files_summary:\n",
    "        print(\"  ✓ Map files found:\")\n",
    "        for theme, count in map_files_summary.items():\n",
    "            print(f\"      {theme}: {count} files\")\n",
    "    else:\n",
    "        issues.append(\"No map_*_data*.csv files found\")\n",
    "    \n",
    "    if issues:\n",
    "        print(\"\\nValidation issues found:\")\n",
    "        for issue in issues:\n",
    "            print(f\"  ❌ {issue}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"\\n✓ All validations passed!\")\n",
    "        return True\n",
    "\n",
    "def inspect_all_base_files():\n",
    "    \"\"\"\n",
    "    Inspect the structure of base.csv and adm2.csv files to understand their actual format.\n",
    "    \"\"\"\n",
    "    base_path = Path(DATA_PATH)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FILE STRUCTURE INSPECTION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Inspect base.csv\n",
    "    base_file = base_path / 'base.csv'\n",
    "    if base_file.exists():\n",
    "        inspect_file(base_file, \"base.csv\")\n",
    "    \n",
    "    # Inspect adm2.csv\n",
    "    adm2_file = base_path / 'adm2.csv'\n",
    "    if adm2_file.exists():\n",
    "        inspect_file(adm2_file, \"adm2.csv\")\n",
    "    \n",
    "    # Inspect a sample map file\n",
    "    sample_map = list(base_path.glob(\"map_*_data*.csv\"))\n",
    "    if sample_map:\n",
    "        inspect_file(sample_map[0], sample_map[0].name)\n",
    "\n",
    "def list_files():\n",
    "    \"\"\"\n",
    "    List all CSV files in the data directory\n",
    "    \"\"\"\n",
    "    base_path = Path(DATA_PATH)\n",
    "    \n",
    "    if not base_path.exists():\n",
    "        print(f\"Error: Directory not found: {DATA_PATH}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nListing CSV files in: {base_path}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    csv_files = list(base_path.glob(\"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"No CSV files found in the directory.\")\n",
    "        return\n",
    "    \n",
    "    # Categorize files\n",
    "    base_files = []\n",
    "    map_files = {}\n",
    "    output_files = []\n",
    "    other_files = []\n",
    "    \n",
    "    for file in sorted(csv_files):\n",
    "        if file.name == 'base.csv' or file.name == 'adm2.csv':\n",
    "            base_files.append(file.name)\n",
    "        elif file.name.startswith('map_') and 'data' in file.name:\n",
    "            # Extract theme\n",
    "            match = re.match(r'map_(.+?)_data\\d+\\.csv', file.name)\n",
    "            if match:\n",
    "                theme = match.group(1)\n",
    "                if theme not in map_files:\n",
    "                    map_files[theme] = []\n",
    "                map_files[theme].append(file.name)\n",
    "        elif file.name.startswith('ago_tbl_'):\n",
    "            output_files.append(file.name)\n",
    "        else:\n",
    "            other_files.append(file.name)\n",
    "    \n",
    "    # Display categorized files\n",
    "    if base_files:\n",
    "        print(\"Base files:\")\n",
    "        for f in base_files:\n",
    "            print(f\"  - {f}\")\n",
    "    \n",
    "    if map_files:\n",
    "        print(\"\\nMap data files by theme:\")\n",
    "        for theme, files in sorted(map_files.items()):\n",
    "            print(f\"  {theme}: {len(files)} files\")\n",
    "            if len(files) <= 3:\n",
    "                for f in sorted(files):\n",
    "                    print(f\"    - {f}\")\n",
    "    \n",
    "    if output_files:\n",
    "        print(\"\\nOutput files (previously generated):\")\n",
    "        for f in output_files:\n",
    "            print(f\"  - {f}\")\n",
    "    \n",
    "    if other_files:\n",
    "        print(\"\\nOther CSV files:\")\n",
    "        for f in other_files:\n",
    "            print(f\"  - {f}\")\n",
    "    \n",
    "    print(f\"\\nTotal: {len(csv_files)} CSV files\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"CSV Data Processing Script\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # List files in directory first\n",
    "    list_files()\n",
    "    \n",
    "    # Inspect the actual structure of the files\n",
    "    inspect_all_base_files()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    # Validate input files\n",
    "    if validate_input_files():\n",
    "        response = input(\"\\nDo you want to proceed with processing? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            print(\"\\nStarting processing...\")\n",
    "            process_csv_files()\n",
    "        else:\n",
    "            print(\"Processing cancelled.\")\n",
    "    else:\n",
    "        print(\"\\nPlease check the file structure above.\")\n",
    "        print(\"The script will automatically detect delimiters (comma, semicolon, tab).\")\n",
    "        print(f\"\\nCurrent data path: {DATA_PATH}\")\n",
    "        print(\"Update the DATA_PATH variable in the script if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28fad67-347c-450d-83b9-71dd705131f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
